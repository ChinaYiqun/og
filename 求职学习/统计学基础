统计分析的目的
	
	更好的推测因果关系 

统计分析的关键概念
	4 种测量尺度 
		1. 定类 尺度
			性别 喜欢的艺人--> 频数分布图
		2.定序 尺度
			喜欢宠物的顺序 --> 频数，顺序平均值
		3.定距 尺度
			10 分满分 1-10 分 --> 频数分布 
		4.定比 尺度 -->		 标准差等


	集中趋势
		均值 算法 > 几何 > 调和
		中位数 
		众数
	离散趋势
		频数分布 标准差 方差 四分位数 极差

统计学两大定理

	大数定律 
	样本 n 越大 ；样本均值几乎等于总体均值

	中心极限定理
	中心极限定理指的是给定一个任意分布的总体。我每次从这些总体中随机抽取 n 个抽样，一共抽 m 次。 然后把这 m 组抽样分别求出平均值。 这些平均值的分布接近正态分布。

统计推断
	抽样误差 与 标准误差
		【引】抽样 如何好好的抽样 -- 
		抽样误差是一个数，标准误差是统计量 
	
	t 分布 
	当 样本量逐渐变大的时候 t分布接近正太分布 【与中心极限定理的思想很接近 30 以上】
	【引 x2卡方分布 正太分布】
	
	参数估计 
	【引 贝叶斯】
	
	假设检验 【大重点！！！】


抽样方法
	
	...

假设检验
	假设检验的基本思想是“小概率事件”原理，其统计推断方法是带有某种概率性质的反证法。小概率思想是指小概率事件在一次试验中基本上不会发生。反证法思想是先提出检验假设，再用适当的统计方法，利用小概率原理，确定假设是否成立。即为了检验一个假设H0是否正确，首先假定该假设H0正确，然后根据样本对假设H0做出接受或拒绝的决策。如果样本观察值导致了“小概率事件”发生，就应拒绝假设H0，否则应接受假设H0 [1]  。
	假设检验中所谓“小概率事件”，并非逻辑中的绝对矛盾，而是基于人们在实践中广泛采用的原则，即小概率事件在一次试验中是几乎不发生的，但概率小到什么程度才能算作“小概率事件”，显然，“小概率事件”的概率越小，否定原假设H0就越有说服力，常记这个概率值为α(0<α<1)，称为检验的显著性水平。对于不同的问题，检验的显著性水平α不一定相同，一般认为，事件发生的概率小于0.1、0.05或0.01等，即“小概率事件” [1]  
两类错误

①当假设H0正确时，小概率事件也有可能发生，此时我们会拒绝假设H0。因而犯了“弃真”的错误，称此为第一类错误，犯第一类错误的概率恰好就是“小概率事件”发生的概率α，即 [1] 
P{拒绝H0/H0为真}=α
②当假设H0不正确，但一次抽样检验未发生不合理结果时，这时我们会接受H0，因而犯了“取伪”的错误，称此为第二类错误，记β为犯第二类错误的概率，即 [1] 
P{接受H0/H0不真}=β
理论上，自然希望犯这两类错误的概率都很小。当样本容量n固定时，α、β不能同时都小，即α变小时，β就变大；而β变小时，α就变大。一般只有当样本容量n增大时，才有可能使两者变小。在实际应用中，一般原则是：控制犯第一类错误的概率，即给定α，然后通过增大样本容量n来减小B。这种着重对第一类错误的概率α加以控制的假设检验称为显著性检验 [1]  。
统计分析、一般线性模型

	t 检验

		检验样本均值 与总体均值是否有差异

		独立样本均值检验 两组独立样本之间的均值是否有差异

		配对样本均值检验	一组样本在不同时间段上是否有差异

	F检验/方差检验/ANOVA
	eg：学历和收入是否有差异 SST = SSA + SSE

		单因素方差检验 一个or多个因变量（连续变量），自变量只有一个（分类变量）

		多因素方差分析 一个因变量（连续变量），自变量有多个（分类变量 连续变量）

		重复方差检验
		一个因变量，在多个时刻重复测量多次，自变量可以有也可以没有

	相关系数

		Pearson相关系数 
		极强相关  0.8 强相关 0.6 中等相关 0.4 若相关 0.2 极弱相关

		Spearman 等级相关系数 【定序】

		Kendall‘s tao-b 等级相关系数【定序】

		然后事实上通常测量两个变量的相关性 会受到其他变量的干扰 x->y

		偏相关性 （控制其他变量）

		典型相关分析 
		两个领域之间的相关性
		宏观经济 和 当地治安水平会不会有相关性？

